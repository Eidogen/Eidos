# Eidos 定时任务服务设计

> 服务名: eidos-jobs
> 语言: Go
>
> **重要**: 本文档包含分布式锁增强、任务幂等性、服务协调等关键设计，请完整阅读。

---

## 一、服务职责

### 1.1 核心定位

Jobs Service 负责系统中所有定时/周期性任务的调度和执行。参考 dYdX v4 的 roundtable 服务设计，精简为 **6 个核心任务**，覆盖对账、清理、聚合等必要功能。

> **设计原则**: 最小化任务数量，只保留必要任务，避免过度设计。

### 1.2 职责边界

| 职责 | 描述 | 属于本服务 |
|------|------|-----------|
| 链上链下对账 | 定期比对链上和链下余额/结算状态 | ✅ |
| 过期订单清理 | 清理超时/过期订单 | ✅ |
| 数据归档 | 历史订单/成交数据归档 | ✅ |
| 统计汇总 | 交易量、手续费等业务统计 | ✅ |
| K线聚合 | 生成大周期K线 (1h/4h/1d) | ✅ |
| 健康监控 | 服务健康检查 + 告警检测 | ✅ |
| 定时结算 | 批量触发链上结算 | ❌ (eidos-chain) |
| 资金费率结算 | 永续合约资金费率结算 | ❌ (待规划) |

### 1.3 对外能力

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      Jobs Service 对外能力                                   │
│                                                                              │
│  定时任务 (6个):                                                             │
│  ───────────────                                                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐              │
│  │  reconciliation │  │  cleanup-orders │  │  archive-data   │              │
│  │  链上链下对账   │  │  清理过期订单   │  │  数据归档       │              │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘              │
│                                                                              │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐              │
│  │  stats-agg      │  │  kline-agg      │  │  health-monitor │              │
│  │  统计汇总       │  │  K线聚合        │  │  健康监控       │              │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘              │
│                                                                              │
│  gRPC 接口:                                                                  │
│  ───────────                                                                 │
│  - GetJobStatus: 查询任务执行状态                                            │
│  - TriggerJob: 手动触发任务 (运营使用)                                       │
│  - GetReconciliationReport: 获取对账报告                                     │
│                                                                              │
│  HTTP 接口 (运维):                                                           │
│  ─────────────────                                                           │
│  - GET /health: 健康检查                                                     │
│  - GET /jobs: 任务列表                                                       │
│  - POST /jobs/{name}/trigger: 手动触发                                       │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 二、任务清单

### 2.1 任务配置表 (6 个核心任务)

| 任务名称 | Cron 表达式 | 执行频率 | 说明 | 参考 (dYdX) |
|---------|------------|---------|------|-------------|
| `reconciliation` | `0 0 * * * *` | 每小时 | 链上链下对账 (余额+结算) | - |
| `cleanup-orders` | `*/2 * * * *` | 每 2 分钟 | 清理过期/取消订单 | `remove_expired_orders` |
| `archive-data` | `0 0 3 * * *` | 每日凌晨 3 点 | 归档历史订单+成交 | - |
| `stats-agg` | `0 5 * * * *` | 每小时 | 统计汇总 (时+日) | - |
| `kline-agg` | `0 1 * * * *` | 每小时 | K线聚合 (1h/4h/1d) | - |
| `health-monitor` | `*/30 * * * * *` | 每 30 秒 | 健康检查 + 告警 | `track_lag` |

> **精简说明**:
> - 原 13 个任务合并为 6 个，减少调度复杂度
> - `reconciliation`: 合并余额对账 + 结算对账
> - `cleanup-orders`: 参考 dYdX `remove_expired_orders` (2min 周期)
> - `archive-data`: 合并订单归档 + 成交归档
> - `stats-agg`: 合并日统计 + 时统计 (在同一任务内按条件执行)
> - `kline-agg`: 合并 1h/4h/1d K线 (在同一任务内按条件生成)
> - `health-monitor`: 合并健康检查 + 告警检测

### 2.2 dYdX v4 对比

dYdX v4 roundtable 有 26+ 任务，但大部分是特有功能 (永续合约、合规、排行榜等)。以下是 Eidos 相关的任务：

| dYdX 任务 | 频率 | Eidos 对应 | 说明 |
|-----------|------|-----------|------|
| `remove_expired_orders` | 2min | `cleanup-orders` | 移除过期订单 |
| `delete_zero_price_levels` | 2min | - | 订单簿维护 (可选) |
| `cancel_stale_orders` | 30s | - | 取消陈旧订单 (可选) |
| `track_lag` | 10s | `health-monitor` | 延迟监控 |

以下 dYdX 任务 **当前不需要**：
- `update_pnl` / `create_pnl_ticks` - 永续合约 PnL
- `update_funding_payments` - 资金费率
- `aggregate_trading_rewards_*` - 交易奖励
- `create_leaderboard_*` - 排行榜
- `update_compliance_*` - 合规检查
- `*_fast_sync_*` - 快速同步快照

### 2.3 任务状态

```
任务执行状态:
├── PENDING: 等待执行
├── RUNNING: 正在执行
├── SUCCESS: 执行成功
├── FAILED: 执行失败 (需告警)
└── SKIPPED: 跳过 (上一轮未完成)
```

---

## 三、核心任务详解

### 3.1 reconciliation - 链上链下对账

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      链上链下对账流程                                        │
│                                                                              │
│  目的: 确保链下余额与链上合约余额一致                                        │
│  ═════════════════════════════════════                                       │
│                                                                              │
│  ┌─────────────────┐                    ┌─────────────────┐                 │
│  │   链下数据库    │                    │   链上合约      │                 │
│  │                 │                    │                 │                 │
│  │  balances 表    │     对比           │  Vault 合约     │                 │
│  │  deposits 表    │  ◄─────────►       │  balanceOf()    │                 │
│  │  withdrawals 表 │                    │  deposited()    │                 │
│  │  trades 表      │                    │  withdrawn()    │                 │
│  └────────┬────────┘                    └────────┬────────┘                 │
│           │                                      │                          │
│           └──────────────────┬───────────────────┘                          │
│                              ▼                                              │
│                    ┌─────────────────┐                                      │
│                    │   对账结果      │                                      │
│                    │                 │                                      │
│                    │  ✅ 一致        │ → 记录日志                           │
│                    │  ❌ 不一致      │ → 生成差异报告 + 告警                │
│                    └─────────────────┘                                      │
│                                                                              │
│  对账维度:                                                                   │
│  ──────────                                                                  │
│  1. 用户余额对账: sum(链下余额) vs sum(链上余额)                            │
│  2. 充值对账: 链下充值记录 vs 链上 Deposit 事件                             │
│  3. 提现对账: 链下提现记录 vs 链上 Withdraw 交易                            │
│  4. 结算对账: 链下成交状态 vs 链上 Settlement 状态                          │
│                                                                              │
│  差异处理:                                                                   │
│  ──────────                                                                  │
│  - 小额差异 (< 0.01 USDC): 记录日志，自动忽略                               │
│  - 中等差异 (0.01 - 100 USDC): 告警通知，人工审核                           │
│  - 大额差异 (> 100 USDC): 紧急告警，暂停相关操作                            │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 3.1.1 增量对账策略

> **问题**: 全量对账在用户规模增大后效率低下，每小时对账可能超时。

**解决方案**: 采用**增量 + 周期性全量**混合策略：

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      增量对账策略                                            │
│                                                                              │
│  对账类型:                                                                   │
│  ──────────                                                                  │
│  1. 增量对账 (每小时): 只对账上一小时有变动的账户                           │
│  2. 全量对账 (每日 02:00): 完整遍历所有账户                                 │
│                                                                              │
│  增量检测方式:                                                               │
│  ──────────────                                                              │
│  - 根据 updated_at 字段筛选近 1 小时有余额变动的用户                        │
│  - 根据 deposits/withdrawals/trades 表筛选近 1 小时有交易的用户             │
│  - 取并集作为增量对账范围                                                   │
│                                                                              │
│  检查点机制:                                                                 │
│  ──────────────                                                              │
│  - 每次对账完成后记录 checkpoint (最后处理的 block_number / timestamp)      │
│  - 下次对账从 checkpoint 开始，避免重复                                     │
│  - 全量对账后重置 checkpoint                                                │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

```go
// 增量对账实现
func (j *ReconciliationJob) ExecuteIncremental(ctx context.Context) error {
    // 1. 获取上次对账的检查点
    checkpoint, err := j.getCheckpoint(ctx)
    if err != nil {
        return err
    }

    // 2. 查询增量变动的账户
    changedAccounts, err := j.accountRepo.FindAccountsChangedSince(ctx, checkpoint.LastTime)
    if err != nil {
        return err
    }

    log.Infof("incremental reconciliation: %d accounts changed since %v",
        len(changedAccounts), checkpoint.LastTime)

    // 3. 批量对账 (避免对链上合约造成压力)
    const batchSize = 100
    for i := 0; i < len(changedAccounts); i += batchSize {
        end := min(i+batchSize, len(changedAccounts))
        batch := changedAccounts[i:end]

        if err := j.reconcileBatch(ctx, batch); err != nil {
            return fmt.Errorf("reconcile batch %d-%d: %w", i, end, err)
        }

        // 更新检查点 (支持中断后恢复)
        j.updateCheckpoint(ctx, batch[len(batch)-1].UpdatedAt)
    }

    return nil
}

// 全量对账 (每日执行)
func (j *ReconciliationJob) ExecuteFull(ctx context.Context) error {
    var cursor string
    for {
        accounts, nextCursor, err := j.accountRepo.ListAccountsPaginated(ctx, cursor, 1000)
        if err != nil {
            return err
        }

        if err := j.reconcileBatch(ctx, accounts); err != nil {
            return err
        }

        if nextCursor == "" {
            break
        }
        cursor = nextCursor
    }

    // 重置检查点
    j.resetCheckpoint(ctx)
    return nil
}
```

**对账记录表**:

```sql
CREATE TABLE reconciliation_records (
    id              BIGINT PRIMARY KEY,
    job_type        VARCHAR(50) NOT NULL,    -- 'balance', 'settlement', etc.
    reconcile_type  VARCHAR(20) NOT NULL,    -- 'incremental', 'full'
    status          VARCHAR(20) NOT NULL,    -- 'matched', 'mismatched'
    wallet_address  VARCHAR(42),
    token           VARCHAR(42),
    offchain_value  DECIMAL(36, 18),
    onchain_value   DECIMAL(36, 18),
    diff_value      DECIMAL(36, 18),
    details         JSONB,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 对账检查点表
CREATE TABLE reconciliation_checkpoints (
    id              SERIAL PRIMARY KEY,
    job_type        VARCHAR(50) NOT NULL UNIQUE,
    last_time       TIMESTAMP NOT NULL,
    last_block      BIGINT,
    updated_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 3.2 cleanup-orders - 清理过期订单

> **重要**: 订单清理必须与撮合引擎协调，避免竞态条件导致订单簿与数据库状态不一致。

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      过期订单清理 (参考 dYdX remove_expired_orders)          │
│                                                                              │
│  执行频率: 每 2 分钟                                                        │
│  ═════════════════════                                                       │
│                                                                              │
│  清理规则:                                                                   │
│  ──────────                                                                  │
│  1. GTT 订单超过 expiry_time → 标记 EXPIRED                                 │
│  2. 已取消订单超过 24 小时 → 清理缓存                                       │
│  3. 零数量挂单 → 移除订单簿                                                 │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 3.2.1 撮合引擎协调机制

**问题**: 如果 jobs-service 直接更新数据库状态，可能与撮合引擎的内存订单簿产生竞态：
- Jobs: 发现订单过期，更新 DB 为 expired
- Matching: 同时收到该订单的成交通知，尝试更新为 filled
- 结果: 数据不一致

**解决方案**: 采用**撮合引擎主导**的协调模式：

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      过期订单清理协调流程                                     │
│                                                                              │
│  ┌─────────────────┐                          ┌─────────────────┐           │
│  │   jobs-service  │                          │ matching-engine │           │
│  │                 │                          │                 │           │
│  │ 1. 发现过期订单 │ ──── ExpireOrder ────►   │ 2. 检查订单簿   │           │
│  │    (只读查询)   │      (gRPC 请求)         │                 │           │
│  │                 │                          │    订单存在?    │           │
│  │                 │                          │    ├─ 是: 移除  │           │
│  │                 │ ◄─── 确认响应 ──────     │    └─ 否: 忽略  │           │
│  │                 │                          │                 │           │
│  │                 │                          │ 3. 发送 Kafka   │           │
│  │                 │                          │    OrderExpired │           │
│  │                 │                          │    事件         │           │
│  └─────────────────┘                          └────────┬────────┘           │
│                                                        │                    │
│                                                        ▼                    │
│                                               ┌─────────────────┐           │
│                                               │ trading-service │           │
│                                               │                 │           │
│                                               │ 4. 消费事件     │           │
│                                               │    更新 DB 状态 │           │
│                                               │    解冻余额     │           │
│                                               └─────────────────┘           │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

**协调规则**:
1. **jobs-service 不直接修改订单状态** - 只负责发现过期订单，发送清理请求
2. **撮合引擎是订单状态的权威来源** - 所有订单状态变更必须通过撮合引擎
3. **通过 Kafka 事件驱动后续处理** - 确保各服务状态最终一致

#### 3.2.2 实现代码

```go
// jobs-service: 发现并请求清理过期订单
func (j *CleanupOrdersJob) Execute(ctx context.Context) error {
    // 1. 查询过期订单 (只读)
    expiredOrders, err := j.orderRepo.FindExpiredOrders(ctx, time.Now())
    if err != nil {
        return fmt.Errorf("find expired orders: %w", err)
    }

    // 2. 批量发送清理请求到撮合引擎
    for _, order := range expiredOrders {
        resp, err := j.matchingClient.ExpireOrder(ctx, &pb.ExpireOrderRequest{
            OrderId:   order.ID,
            Reason:    pb.ExpireReason_TTL_EXCEEDED,
            RequestId: uuid.New().String(), // 幂等性 ID
        })
        if err != nil {
            log.Warnf("expire order %s failed: %v", order.ID, err)
            continue
        }

        if resp.Status == pb.ExpireStatus_ALREADY_PROCESSED {
            log.Debugf("order %s already expired/cancelled", order.ID)
        }
    }

    return nil
}

// matching-engine: 处理过期请求
func (m *MatchingEngine) ExpireOrder(ctx context.Context, req *pb.ExpireOrderRequest) (*pb.ExpireOrderResponse, error) {
    // 幂等性检查
    if m.isRequestProcessed(req.RequestId) {
        return &pb.ExpireOrderResponse{Status: pb.ExpireStatus_ALREADY_PROCESSED}, nil
    }

    m.mu.Lock()
    defer m.mu.Unlock()

    // 从订单簿移除
    order, found := m.orderBook.Remove(req.OrderId)
    if !found {
        m.markRequestProcessed(req.RequestId)
        return &pb.ExpireOrderResponse{Status: pb.ExpireStatus_NOT_FOUND}, nil
    }

    // 发送过期事件到 Kafka
    m.publishOrderExpired(order, req.Reason)

    m.markRequestProcessed(req.RequestId)
    return &pb.ExpireOrderResponse{Status: pb.ExpireStatus_EXPIRED}, nil
}
```

### 3.3 archive-data - 数据归档

> **重要**: 大批量数据归档需要采用分批处理，避免长事务锁表影响在线服务。

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      数据归档策略                                            │
│                                                                              │
│  执行频率: 每日凌晨 3 点                                                    │
│  ═════════════════════════                                                   │
│                                                                              │
│  归档规则:                                                                   │
│  ──────────                                                                  │
│  1. 已完成订单 (filled/cancelled/expired) 超过 30 天 → 归档                 │
│  2. 已结算成交记录超过 30 天 → 归档                                         │
│  3. 归档数据保留 2 年后删除                                                 │
│                                                                              │
│  归档流程:                                                                   │
│  ──────────                                                                  │
│  主表 (orders) ──归档──> 归档表 (orders_archive)                            │
│  主表 (trades) ──归档──> 归档表 (trades_archive)                            │
│       ↓                         ↓                                           │
│    热数据                   冷数据 (只读)                                    │
│  (高频查询)               (偶尔查询)                                        │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 3.3.1 批量归档实现

**问题**: 一次性归档大量数据会导致：
1. 长事务锁表，影响在线交易
2. 内存占用过高
3. 任务执行时间过长，可能超时

**解决方案**: 分批归档 + 进度检查点：

```go
// 批量归档实现
func (j *ArchiveDataJob) Execute(ctx context.Context) error {
    const batchSize = 1000
    cutoffTime := time.Now().AddDate(0, 0, -30)

    // 1. 获取上次归档进度 (支持中断恢复)
    progress, err := j.getArchiveProgress(ctx)
    if err != nil {
        return err
    }

    // 2. 分批归档订单
    for {
        archived, lastID, err := j.archiveOrdersBatch(ctx, cutoffTime, progress.LastOrderID, batchSize)
        if err != nil {
            return fmt.Errorf("archive orders: %w", err)
        }

        if archived == 0 {
            break
        }

        // 更新进度检查点
        progress.LastOrderID = lastID
        j.saveArchiveProgress(ctx, progress)

        log.Infof("archived %d orders, last_id=%d", archived, lastID)

        // 每批之间短暂休眠，减少对在线服务的影响
        time.Sleep(100 * time.Millisecond)
    }

    // 3. 分批归档成交记录 (类似逻辑)
    for {
        archived, lastID, err := j.archiveTradesBatch(ctx, cutoffTime, progress.LastTradeID, batchSize)
        if err != nil {
            return fmt.Errorf("archive trades: %w", err)
        }

        if archived == 0 {
            break
        }

        progress.LastTradeID = lastID
        j.saveArchiveProgress(ctx, progress)

        time.Sleep(100 * time.Millisecond)
    }

    // 4. 重置进度 (归档完成)
    j.resetArchiveProgress(ctx)
    return nil
}

// 单批归档订单 (事务内完成)
func (j *ArchiveDataJob) archiveOrdersBatch(ctx context.Context, cutoff time.Time, lastID int64, limit int) (int, int64, error) {
    tx, err := j.db.BeginTx(ctx, nil)
    if err != nil {
        return 0, 0, err
    }
    defer tx.Rollback()

    // 1. 查询待归档订单
    rows, err := tx.QueryContext(ctx, `
        SELECT id, user_id, market, side, type, price, quantity, status, created_at, updated_at
        FROM orders
        WHERE id > $1
          AND status IN ('filled', 'cancelled', 'expired')
          AND updated_at < $2
        ORDER BY id
        LIMIT $3
    `, lastID, cutoff, limit)
    if err != nil {
        return 0, 0, err
    }
    defer rows.Close()

    var orders []Order
    var maxID int64
    for rows.Next() {
        var o Order
        if err := rows.Scan(&o.ID, &o.UserID, &o.Market, &o.Side, &o.Type,
            &o.Price, &o.Quantity, &o.Status, &o.CreatedAt, &o.UpdatedAt); err != nil {
            return 0, 0, err
        }
        orders = append(orders, o)
        maxID = o.ID
    }

    if len(orders) == 0 {
        return 0, lastID, nil
    }

    // 2. 批量插入归档表
    if err := j.bulkInsertArchive(tx, "orders_archive", orders); err != nil {
        return 0, 0, err
    }

    // 3. 批量删除主表 (只删除已成功插入归档表的记录)
    ids := make([]int64, len(orders))
    for i, o := range orders {
        ids[i] = o.ID
    }
    if _, err := tx.ExecContext(ctx,
        `DELETE FROM orders WHERE id = ANY($1)`, pq.Array(ids)); err != nil {
        return 0, 0, err
    }

    if err := tx.Commit(); err != nil {
        return 0, 0, err
    }

    return len(orders), maxID, nil
}
```

#### 3.3.2 归档进度表

```sql
-- 归档进度检查点表 (支持中断恢复)
CREATE TABLE archive_progress (
    id              SERIAL PRIMARY KEY,
    table_name      VARCHAR(50) NOT NULL UNIQUE,
    last_id         BIGINT NOT NULL DEFAULT 0,
    started_at      TIMESTAMP,
    updated_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 归档表需要创建相同的索引结构
CREATE TABLE orders_archive (LIKE orders INCLUDING ALL);
CREATE TABLE trades_archive (LIKE trades INCLUDING ALL);
```

### 3.4 stats-agg - 统计汇总

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      统计汇总任务                                            │
│                                                                              │
│  执行频率: 每小时第 5 分钟                                                  │
│  ══════════════════════════                                                  │
│                                                                              │
│  执行逻辑:                                                                   │
│  ──────────                                                                  │
│  每次执行时:                                                                │
│  - 生成过去 1 小时的时统计                                                  │
│  - 如果是 00:05，额外生成昨日的日统计                                       │
│                                                                              │
│  统计指标:                                                                   │
│  ──────────                                                                  │
│  - 交易量 (按交易对)                                                        │
│  - 成交笔数                                                                 │
│  - 手续费收入                                                               │
│  - 活跃用户数 (仅日统计)                                                    │
│  - 新增用户数 (仅日统计)                                                    │
│  - 充值/提现金额 (仅日统计)                                                 │
│                                                                              │
│  存储: 写入 statistics 表，按时间分区                                       │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.5 kline-agg - K线聚合

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      K线聚合任务                                             │
│                                                                              │
│  执行频率: 每小时第 1 分钟                                                  │
│  ══════════════════════════                                                  │
│                                                                              │
│  1分钟K线 (实时生成):                                                        │
│  ─────────────────────                                                       │
│  - 由 market-service 实时生成，不属于 jobs-service                          │
│                                                                              │
│  大周期K线 (定时聚合):                                                       │
│  ─────────────────────                                                       │
│  每次执行时:                                                                │
│  - 生成过去 1 小时的 1h K线                                                 │
│  - 如果是 0/4/8/12/16/20 点，额外生成 4h K线                                │
│  - 如果是 00:01，额外生成昨日的 1d K线                                      │
│                                                                              │
│  聚合逻辑:                                                                   │
│  ──────────                                                                  │
│  open  = 第一根K线的 open                                                   │
│  high  = max(所有K线的 high)                                                │
│  low   = min(所有K线的 low)                                                 │
│  close = 最后一根K线的 close                                                │
│  volume = sum(所有K线的 volume)                                             │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.6 health-monitor - 健康监控

> **设计说明**: 健康监控是只读操作，**无需分布式锁**。多节点同时执行无害，反而提高监控覆盖率。

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      健康监控任务                                            │
│                                                                              │
│  执行频率: 每 30 秒                                                         │
│  锁策略: 无需锁 (只读操作，多节点执行无害)                                  │
│  ═════════════════════════════════════════                                   │
│                                                                              │
│  健康检查:                                                                   │
│  ──────────                                                                  │
│  - 检查所有服务的 /health 端点                                              │
│  - 检查 PostgreSQL / Redis / Kafka 连接状态                                 │
│  - 检查磁盘/内存使用率                                                      │
│                                                                              │
│  告警检测:                                                                   │
│  ──────────                                                                  │
│  - 服务响应超时 > 5s → Warning                                              │
│  - 服务连续 3 次无响应 → Critical                                           │
│  - 对账差异金额 > 100 USDC → Critical                                       │
│  - 定时任务超过 2 个周期未执行 → Critical                                   │
│                                                                              │
│  告警渠道:                                                                   │
│  ──────────                                                                  │
│  - Slack / 钉钉 / 企业微信                                                  │
│  - PagerDuty (Critical 级别)                                                │
│  - 邮件 (每日汇总)                                                          │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 3.6.1 告警去重

多节点执行时需要避免重复告警：

```go
// 告警去重：使用 Redis 记录已发送的告警
func (j *HealthMonitorJob) sendAlertWithDedup(ctx context.Context, alert Alert) error {
    // 告警去重 Key: alert_type:target:level
    dedupKey := fmt.Sprintf("alert:sent:%s:%s:%s", alert.Type, alert.Target, alert.Level)

    // 检查是否已在冷却期内发送过
    exists, err := j.redis.Exists(ctx, dedupKey).Result()
    if err != nil {
        return err
    }
    if exists > 0 {
        log.Debugf("alert already sent, skipping: %s", dedupKey)
        return nil
    }

    // 发送告警
    if err := j.alertClient.Send(ctx, alert); err != nil {
        return err
    }

    // 设置冷却期 (避免告警风暴)
    cooldown := j.getCooldownDuration(alert.Level) // Warning=5min, Critical=1min
    j.redis.Set(ctx, dedupKey, "1", cooldown)

    return nil
}
```

---

## 四、任务调度架构

### 4.1 调度器设计

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      任务调度架构                                            │
│                                                                              │
│                        ┌─────────────────┐                                  │
│                        │   Scheduler     │                                  │
│                        │   (调度器)      │                                  │
│                        │                 │                                  │
│                        │  - Cron 解析    │                                  │
│                        │  - 任务触发     │                                  │
│                        │  - 并发控制     │                                  │
│                        └────────┬────────┘                                  │
│                                 │                                           │
│              ┌──────────────────┼──────────────────┐                        │
│              │                  │                  │                        │
│              ▼                  ▼                  ▼                        │
│     ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐             │
│     │   JobWorker 1   │ │   JobWorker 2   │ │   JobWorker N   │             │
│     │                 │ │                 │ │                 │             │
│     │ reconciliation  │ │   archive       │ │   stats         │             │
│     └─────────────────┘ └─────────────────┘ └─────────────────┘             │
│                                                                              │
│  调度策略:                                                                   │
│  ──────────                                                                  │
│  1. 分布式锁: 使用 Redis 锁确保同一任务只在一个节点执行                     │
│  2. 任务隔离: 不同类型任务使用不同 Worker Pool                              │
│  3. 超时控制: 每个任务有最大执行时间限制                                    │
│  4. 失败重试: 失败后按退避算法重试 (最多 3 次)                              │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 分布式锁 (防止重复执行)

> **问题**: 简单的 SetNX + TTL 方式存在风险：如果任务执行时间超过 TTL，锁会自动释放，导致其他节点重复执行。

#### 4.2.1 基础实现 (不推荐用于长任务)

```go
// ⚠️ 基础实现 - 仅适用于执行时间远小于 TTL 的短任务
func (s *Scheduler) executeWithLock(jobName string, fn func() error) error {
    lockKey := fmt.Sprintf("eidos:job:lock:%s", jobName)

    // 获取锁，TTL = 任务超时时间
    acquired, err := s.redis.SetNX(ctx, lockKey, "1", jobTimeout).Result()
    if err != nil || !acquired {
        return ErrJobAlreadyRunning
    }
    defer s.redis.Del(ctx, lockKey)

    return fn()
}
```

#### 4.2.2 Watchdog 模式 (推荐)

对于可能长时间运行的任务 (如 `reconciliation`、`archive-data`)，使用 Watchdog 模式自动续期：

```go
// Watchdog 模式分布式锁 - 自动续期，避免任务执行期间锁过期
type WatchdogLock struct {
    redis     *redis.Client
    lockKey   string
    lockValue string        // 唯一标识，用于安全释放
    ttl       time.Duration
    stopCh    chan struct{}
    wg        sync.WaitGroup
}

func (s *Scheduler) executeWithWatchdog(ctx context.Context, jobName string, fn func(context.Context) error) error {
    lockKey := fmt.Sprintf("eidos:job:lock:%s", jobName)
    lockValue := uuid.New().String()  // 唯一标识，确保只释放自己的锁
    baseTTL := 30 * time.Second       // 基础 TTL
    renewInterval := 10 * time.Second // 续期间隔 (TTL 的 1/3)

    // 1. 获取锁
    acquired, err := s.redis.SetNX(ctx, lockKey, lockValue, baseTTL).Result()
    if err != nil || !acquired {
        return ErrJobAlreadyRunning
    }

    // 2. 启动 Watchdog 协程，定期续期
    stopWatchdog := make(chan struct{})
    var wg sync.WaitGroup
    wg.Add(1)
    go func() {
        defer wg.Done()
        ticker := time.NewTicker(renewInterval)
        defer ticker.Stop()
        for {
            select {
            case <-stopWatchdog:
                return
            case <-ticker.C:
                // 只有锁值匹配时才续期 (Lua 脚本保证原子性)
                renewed, _ := s.renewLock(ctx, lockKey, lockValue, baseTTL)
                if !renewed {
                    log.Warn("watchdog: failed to renew lock, another process may have taken over")
                    return
                }
            }
        }
    }()

    // 3. 执行任务
    execErr := fn(ctx)

    // 4. 停止 Watchdog
    close(stopWatchdog)
    wg.Wait()

    // 5. 安全释放锁 (只释放自己的锁)
    s.releaseLock(ctx, lockKey, lockValue)

    return execErr
}

// Lua 脚本：原子续期 (只有锁值匹配时才续期)
var renewLockScript = redis.NewScript(`
    if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("PEXPIRE", KEYS[1], ARGV[2])
    else
        return 0
    end
`)

func (s *Scheduler) renewLock(ctx context.Context, key, value string, ttl time.Duration) (bool, error) {
    result, err := renewLockScript.Run(ctx, s.redis, []string{key}, value, ttl.Milliseconds()).Int()
    return result == 1, err
}

// Lua 脚本：安全释放锁 (只释放自己的锁)
var releaseLockScript = redis.NewScript(`
    if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("DEL", KEYS[1])
    else
        return 0
    end
`)

func (s *Scheduler) releaseLock(ctx context.Context, key, value string) error {
    _, err := releaseLockScript.Run(ctx, s.redis, []string{key}, value).Int()
    return err
}
```

#### 4.2.3 任务类型与锁策略

| 任务 | 执行频率 | 预计耗时 | 锁策略 |
|------|---------|---------|--------|
| `health-monitor` | 30s | <1s | **无需锁** (只读操作，多节点执行无害) |
| `cleanup-orders` | 2min | <30s | 基础锁 (TTL=1min) |
| `stats-agg` | 1h | <1min | 基础锁 (TTL=5min) |
| `kline-agg` | 1h | <1min | 基础锁 (TTL=5min) |
| `reconciliation` | 1h | 1-10min | **Watchdog 锁** |
| `archive-data` | 1d | 10-30min | **Watchdog 锁** |

### 4.3 任务幂等性设计

> **原则**: 所有任务必须是幂等的，即重复执行不会产生副作用。这是应对任务失败重试、节点故障等场景的关键。

#### 4.3.1 幂等性策略

| 任务 | 幂等性实现 | 说明 |
|------|-----------|------|
| `reconciliation` | 检查点 + 增量处理 | 每次从上次检查点继续，已处理数据不重复处理 |
| `cleanup-orders` | 请求级幂等 ID | 每个清理请求携带唯一 ID，撮合引擎去重 |
| `archive-data` | 进度记录 + 事务归档 | 记录已归档的最大 ID，事务保证原子性 |
| `stats-agg` | UPSERT 语义 | 统计记录使用 UPSERT，重复执行更新而非插入 |
| `kline-agg` | UPSERT 语义 | K线记录使用 UPSERT，重复执行覆盖 |
| `health-monitor` | 天然幂等 | 只读操作，重复执行无副作用 |

#### 4.3.2 UPSERT 示例 (stats-agg)

```go
// 统计任务使用 UPSERT 保证幂等
func (j *StatsAggJob) upsertHourlyStat(ctx context.Context, stat HourlyStat) error {
    _, err := j.db.ExecContext(ctx, `
        INSERT INTO statistics (stat_type, stat_date, stat_hour, market, metric_name, metric_value)
        VALUES ('hourly', $1, $2, $3, $4, $5)
        ON CONFLICT (stat_type, stat_date, stat_hour, market, metric_name)
        DO UPDATE SET metric_value = EXCLUDED.metric_value, updated_at = NOW()
    `, stat.Date, stat.Hour, stat.Market, stat.MetricName, stat.MetricValue)
    return err
}
```

需要对应的唯一约束：

```sql
ALTER TABLE statistics ADD CONSTRAINT uk_statistics_type_date_hour_market_metric
    UNIQUE (stat_type, stat_date, stat_hour, market, metric_name);
```

#### 4.3.3 任务执行记录去重

使用执行记录表防止同一时间窗口重复执行：

```go
// 任务执行前检查是否已执行
func (j *BaseJob) checkAndRecordExecution(ctx context.Context, jobName string, windowKey string) (bool, error) {
    // windowKey 示例: "2026-01-15T10:00" (表示某小时的统计任务)
    execKey := fmt.Sprintf("job:executed:%s:%s", jobName, windowKey)

    // 原子操作：尝试标记为已执行
    set, err := j.redis.SetNX(ctx, execKey, "1", 24*time.Hour).Result()
    if err != nil {
        return false, err
    }

    if !set {
        log.Infof("job %s for window %s already executed, skipping", jobName, windowKey)
        return false, nil // 已执行过
    }

    return true, nil // 可以执行
}

// stats-agg 任务使用
func (j *StatsAggJob) Execute(ctx context.Context) error {
    // 计算当前要处理的时间窗口
    windowTime := time.Now().Truncate(time.Hour).Add(-time.Hour)
    windowKey := windowTime.Format("2006-01-02T15:04")

    // 检查是否已执行
    shouldRun, err := j.checkAndRecordExecution(ctx, "stats-agg-hourly", windowKey)
    if err != nil {
        return err
    }
    if !shouldRun {
        return nil // 跳过已执行的窗口
    }

    // 执行统计逻辑
    return j.aggregateHourlyStats(ctx, windowTime)
}
```

---

## 五、监控与告警

### 5.1 监控指标

| 指标 | 类型 | 说明 |
|------|------|------|
| `job_execution_total` | Counter | 任务执行总次数 |
| `job_execution_duration_seconds` | Histogram | 任务执行耗时 |
| `job_failures_total` | Counter | 任务失败次数 |
| `job_last_success_timestamp` | Gauge | 上次成功执行时间 |
| `reconciliation_diff_count` | Gauge | 对账差异数量 |
| `reconciliation_diff_amount` | Gauge | 对账差异金额 |

### 5.2 告警规则

| 规则 | 条件 | 级别 |
|------|------|------|
| `JobExecutionFailed` | 任务执行失败 | Warning |
| `JobExecutionTimeout` | 任务超时未完成 | Warning |
| `ReconciliationMismatch` | 对账发现差异 | Critical |
| `JobNotExecuted` | 任务超过 2 个周期未执行 | Critical |

---

## 六、配置示例

```yaml
# eidos-jobs 配置 (精简版 - 6 个核心任务)
service:
  name: eidos-jobs
  grpc_port: 50057
  http_port: 8080

scheduler:
  max_concurrent_jobs: 3          # 最大并发任务数
  default_timeout: 5m             # 默认任务超时

jobs:
  # 1. 链上链下对账
  reconciliation:
    cron: "0 0 * * * *"           # 每小时整点
    timeout: 10m
    enabled: true

  # 2. 清理过期订单 (参考 dYdX remove_expired_orders)
  cleanup-orders:
    cron: "*/2 * * * *"           # 每 2 分钟
    timeout: 1m
    enabled: true

  # 3. 数据归档
  archive-data:
    cron: "0 0 3 * * *"           # 每日凌晨 3 点
    timeout: 30m
    retention_days: 30
    enabled: true

  # 4. 统计汇总
  stats-agg:
    cron: "0 5 * * * *"           # 每小时第 5 分钟
    timeout: 5m
    enabled: true

  # 5. K线聚合
  kline-agg:
    cron: "0 1 * * * *"           # 每小时第 1 分钟
    timeout: 5m
    enabled: true

  # 6. 健康监控
  health-monitor:
    cron: "*/30 * * * * *"        # 每 30 秒
    timeout: 10s
    enabled: true

redis:
  lock_prefix: "eidos:job:lock"
  lock_ttl: 10m
```

---

## 七、数据库表

```sql
-- 任务执行记录表
CREATE TABLE job_executions (
    id              BIGINT PRIMARY KEY,
    job_name        VARCHAR(100) NOT NULL,
    status          VARCHAR(20) NOT NULL,  -- 'running', 'success', 'failed'
    started_at      TIMESTAMP NOT NULL,
    finished_at     TIMESTAMP,
    duration_ms     INT,
    error_message   TEXT,
    result          JSONB,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_job_executions_name_time ON job_executions(job_name, started_at);

-- 统计表
CREATE TABLE statistics (
    id              BIGINT PRIMARY KEY,
    stat_type       VARCHAR(50) NOT NULL,   -- 'daily', 'hourly'
    stat_date       DATE NOT NULL,
    stat_hour       INT,                    -- 0-23, only for hourly
    market          VARCHAR(32),            -- NULL for global stats
    metric_name     VARCHAR(100) NOT NULL,
    metric_value    DECIMAL(36, 18) NOT NULL,
    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_statistics_type_date ON statistics(stat_type, stat_date);
CREATE INDEX idx_statistics_market ON statistics(market, stat_date);
```

---

